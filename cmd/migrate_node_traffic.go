package cmd

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"time"

	"github.com/google/uuid"
	"github.com/xvv6u577/logv2fs/database"
	"github.com/xvv6u577/logv2fs/model"
	"go.mongodb.org/mongo-driver/bson"
	"go.mongodb.org/mongo-driver/mongo/options"
	"gorm.io/datatypes"
	"gorm.io/gorm"
)

// migrateNodeTrafficLogsDataImpl NodeTrafficLogsæ•°æ®è¿ç§»çš„å…·ä½“å®ç°
func migrateNodeTrafficLogsDataImpl(batchSize int, skipExisting bool, stats *model.MigrationStats) error {
	log.Println("ğŸŒ å¼€å§‹è¿ç§»NodeTrafficLogsæ•°æ®...")

	// è·å–æ•°æ®åº“è¿æ¥
	postgresDB := database.GetPostgresDB()

	// è·å–MongoDBé›†åˆ
	collection := database.GetCollection(model.NodeTrafficLogs{})

	// è®¡ç®—æ€»æ•°
	totalCount, err := collection.CountDocuments(context.Background(), bson.M{})
	if err != nil {
		return fmt.Errorf("è·å–NodeTrafficLogsæ€»æ•°å¤±è´¥: %v", err)
	}

	log.Printf("ğŸ“Š å‘ç° %d ä¸ªNodeTrafficLogsè®°å½•éœ€è¦è¿ç§»", totalCount)

	// åˆ†æ‰¹å¤„ç†
	var processed int64 = 0
	var migrated int64 = 0
	var skipped int64 = 0

	for skip := int64(0); skip < totalCount; skip += int64(batchSize) {
		// è®¾ç½®æŸ¥è¯¢é€‰é¡¹
		findOptions := options.Find()
		findOptions.SetSkip(skip)
		findOptions.SetLimit(int64(batchSize))

		// æŸ¥è¯¢ä¸€æ‰¹æ•°æ®
		cursor, err := collection.Find(context.Background(), bson.M{}, findOptions)
		if err != nil {
			return fmt.Errorf("æŸ¥è¯¢NodeTrafficLogsæ•°æ®å¤±è´¥: %v", err)
		}

		// å¤„ç†è¿™æ‰¹æ•°æ®
		var mongoNodeLogs []model.NodeTrafficLogs
		if err := cursor.All(context.Background(), &mongoNodeLogs); err != nil {
			cursor.Close(context.Background())
			return fmt.Errorf("è§£æNodeTrafficLogsæ•°æ®å¤±è´¥: %v", err)
		}
		cursor.Close(context.Background())

		// è½¬æ¢å¹¶ä¿å­˜åˆ°PostgreSQL
		for _, mongoNodeLog := range mongoNodeLogs {
			processed++

			// æ£€æŸ¥æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„è®°å½•
			if skipExisting {
				var existingCount int64
				err := postgresDB.Model(&model.NodeTrafficLogsPG{}).
					Where("domain_as_id = ?", mongoNodeLog.Domain_As_Id).
					Count(&existingCount).Error
				if err != nil {
					log.Printf("âš ï¸  æ£€æŸ¥NodeTrafficLogsé‡å¤å¤±è´¥: %v", err)
					stats.Errors = append(stats.Errors, fmt.Sprintf("æ£€æŸ¥NodeTrafficLogsé‡å¤å¤±è´¥: %v", err))
					continue
				}

				if existingCount > 0 {
					skipped++
					continue
				}
			}

			// è½¬æ¢æ•°æ®ç»“æ„
			pgNodeLog, err := convertNodeTrafficLogsToPG(mongoNodeLog, postgresDB)
			if err != nil {
				log.Printf("âš ï¸  è½¬æ¢NodeTrafficLogså¤±è´¥: %v", err)
				stats.Errors = append(stats.Errors, fmt.Sprintf("è½¬æ¢NodeTrafficLogså¤±è´¥: %v", err))
				continue
			}

			// æ•°æ®éªŒè¯
			if err := validateNodeTrafficLogsData(&pgNodeLog); err != nil {
				log.Printf("âš ï¸  NodeTrafficLogsæ•°æ®éªŒè¯å¤±è´¥: %v", err)
				stats.Errors = append(stats.Errors, fmt.Sprintf("NodeTrafficLogsæ•°æ®éªŒè¯å¤±è´¥: %v", err))
				continue
			}

			// ä¿å­˜åˆ°PostgreSQL
			if err := postgresDB.Create(&pgNodeLog).Error; err != nil {
				log.Printf("âš ï¸  ä¿å­˜NodeTrafficLogså¤±è´¥: %v", err)
				stats.Errors = append(stats.Errors, fmt.Sprintf("ä¿å­˜NodeTrafficLogså¤±è´¥: %v", err))
				continue
			}

			migrated++
		}

		// æ‰“å°è¿›åº¦
		if processed%int64(batchSize*5) == 0 || processed == totalCount {
			log.Printf("ğŸ“ˆ NodeTrafficLogsè¿ç§»è¿›åº¦: %d/%d (å·²è¿ç§»: %d, å·²è·³è¿‡: %d)",
				processed, totalCount, migrated, skipped)
		}
	}

	stats.NodeRecordsMigrated = migrated
	log.Printf("âœ… NodeTrafficLogsè¿ç§»å®Œæˆ: å…±å¤„ç† %d æ¡è®°å½•ï¼ŒæˆåŠŸè¿ç§» %d æ¡ï¼Œè·³è¿‡ %d æ¡",
		processed, migrated, skipped)

	return nil
}

// convertNodeTrafficLogsToPG å°†MongoDBçš„NodeTrafficLogsè½¬æ¢ä¸ºPostgreSQLçš„NodeTrafficLogsPG
func convertNodeTrafficLogsToPG(mongoNodeLog model.NodeTrafficLogs, db *gorm.DB) (model.NodeTrafficLogsPG, error) {
	pgNodeLog := model.NodeTrafficLogsPG{
		ID:         uuid.New(),
		DomainAsId: mongoNodeLog.Domain_As_Id,
		Remark:     mongoNodeLog.Remark,
		Status:     mongoNodeLog.Status,
		CreatedAt:  mongoNodeLog.CreatedAt,
		UpdatedAt:  mongoNodeLog.UpdatedAt,
	}

	// è½¬æ¢æ—¶é—´åºåˆ—æ•°æ®ä¸ºJSONB
	var err error

	// è½¬æ¢HourlyLogs
	if len(mongoNodeLog.HourlyLogs) > 0 {
		hourlyJSON, err := convertNodeHourlyLogsToJSON(mongoNodeLog.HourlyLogs)
		if err != nil {
			return pgNodeLog, fmt.Errorf("è½¬æ¢HourlyLogså¤±è´¥: %v", err)
		}
		pgNodeLog.HourlyLogs = hourlyJSON
	}

	// è½¬æ¢DailyLogs
	if len(mongoNodeLog.DailyLogs) > 0 {
		dailyJSON, err := convertNodeDailyLogsToJSON(mongoNodeLog.DailyLogs)
		if err != nil {
			return pgNodeLog, fmt.Errorf("è½¬æ¢DailyLogså¤±è´¥: %v", err)
		}
		pgNodeLog.DailyLogs = dailyJSON
	}

	// è½¬æ¢MonthlyLogs
	if len(mongoNodeLog.MonthlyLogs) > 0 {
		monthlyJSON, err := convertNodeMonthlyLogsToJSON(mongoNodeLog.MonthlyLogs)
		if err != nil {
			return pgNodeLog, fmt.Errorf("è½¬æ¢MonthlyLogså¤±è´¥: %v", err)
		}
		pgNodeLog.MonthlyLogs = monthlyJSON
	}

	// è½¬æ¢YearlyLogs
	if len(mongoNodeLog.YearlyLogs) > 0 {
		yearlyJSON, err := convertNodeYearlyLogsToJSON(mongoNodeLog.YearlyLogs)
		if err != nil {
			return pgNodeLog, fmt.Errorf("è½¬æ¢YearlyLogså¤±è´¥: %v", err)
		}
		pgNodeLog.YearlyLogs = yearlyJSON
	}

	// å°è¯•å…³è”Domain
	err = linkDomainToNodeTrafficLogs(&pgNodeLog, db)
	if err != nil {
		log.Printf("âš ï¸  å…³è”Domainå¤±è´¥: %v", err)
		// ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­å¤„ç†ï¼Œåªæ˜¯æ²¡æœ‰å¤–é”®å…³è”
	}

	return pgNodeLog, nil
}

// linkDomainToNodeTrafficLogs éªŒè¯NodeTrafficLogså…³è”çš„åŸŸåæ˜¯å¦å­˜åœ¨
func linkDomainToNodeTrafficLogs(pgNodeLog *model.NodeTrafficLogsPG, db *gorm.DB) error {
	// æ ¹æ®domain_as_idæŸ¥æ‰¾å¯¹åº”çš„SubscriptionNode
	var node model.SubscriptionNodePG
	err := db.Where("domain = ?", pgNodeLog.DomainAsId).First(&node).Error
	if err != nil {
		if err == gorm.ErrRecordNotFound {
			// å¯¹åº”çš„SubscriptionNodeä¸å­˜åœ¨ï¼Œä½†ä»ç„¶å¯ä»¥åˆ›å»ºè®°å½•
			log.Printf("âš ï¸  æ‰¾ä¸åˆ°åŒ¹é…çš„SubscriptionNode: %s", pgNodeLog.DomainAsId)
			return nil
		}
		return fmt.Errorf("æŸ¥æ‰¾SubscriptionNodeå¤±è´¥: %v", err)
	}

	// æ‰¾åˆ°äº†åŒ¹é…çš„SubscriptionNodeï¼Œè®°å½•æˆåŠŸ
	log.Printf("âœ… æ‰¾åˆ°åŒ¹é…çš„SubscriptionNode: %s", node.Remark)
	return nil
}

// convertNodeHourlyLogsToJSON è½¬æ¢èŠ‚ç‚¹å°æ—¶çº§åˆ«æ—¥å¿—ä¸ºJSON
func convertNodeHourlyLogsToJSON(hourlyLogs []struct {
	Timestamp time.Time `json:"timestamp" bson:"timestamp"`
	Traffic   int64     `json:"traffic" bson:"traffic"`
}) (datatypes.JSON, error) {
	var logs []model.TrafficLogEntry

	for _, log := range hourlyLogs {
		logs = append(logs, model.TrafficLogEntry{
			Timestamp: log.Timestamp,
			Traffic:   log.Traffic,
		})
	}

	jsonData, err := json.Marshal(logs)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–èŠ‚ç‚¹å°æ—¶æ—¥å¿—å¤±è´¥: %v", err)
	}

	return datatypes.JSON(jsonData), nil
}

// convertNodeDailyLogsToJSON è½¬æ¢èŠ‚ç‚¹æ—¥çº§åˆ«æ—¥å¿—ä¸ºJSON
func convertNodeDailyLogsToJSON(dailyLogs []struct {
	Date    string `json:"date" bson:"date"`
	Traffic int64  `json:"traffic" bson:"traffic"`
}) (datatypes.JSON, error) {
	var logs []model.DailyLogEntry

	for _, log := range dailyLogs {
		logs = append(logs, model.DailyLogEntry{
			Date:    log.Date,
			Traffic: log.Traffic,
		})
	}

	jsonData, err := json.Marshal(logs)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–èŠ‚ç‚¹æ—¥çº§æ—¥å¿—å¤±è´¥: %v", err)
	}

	return datatypes.JSON(jsonData), nil
}

// convertNodeMonthlyLogsToJSON è½¬æ¢èŠ‚ç‚¹æœˆçº§åˆ«æ—¥å¿—ä¸ºJSON
func convertNodeMonthlyLogsToJSON(monthlyLogs []struct {
	Month   string `json:"month" bson:"month"`
	Traffic int64  `json:"traffic" bson:"traffic"`
}) (datatypes.JSON, error) {
	var logs []model.MonthlyLogEntry

	for _, log := range monthlyLogs {
		logs = append(logs, model.MonthlyLogEntry{
			Month:   log.Month,
			Traffic: log.Traffic,
		})
	}

	jsonData, err := json.Marshal(logs)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–èŠ‚ç‚¹æœˆçº§æ—¥å¿—å¤±è´¥: %v", err)
	}

	return datatypes.JSON(jsonData), nil
}

// convertNodeYearlyLogsToJSON è½¬æ¢èŠ‚ç‚¹å¹´çº§åˆ«æ—¥å¿—ä¸ºJSON
func convertNodeYearlyLogsToJSON(yearlyLogs []struct {
	Year    string `json:"year" bson:"year"`
	Traffic int64  `json:"traffic" bson:"traffic"`
}) (datatypes.JSON, error) {
	var logs []model.YearlyLogEntry

	for _, log := range yearlyLogs {
		logs = append(logs, model.YearlyLogEntry{
			Year:    log.Year,
			Traffic: log.Traffic,
		})
	}

	jsonData, err := json.Marshal(logs)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–èŠ‚ç‚¹å¹´çº§æ—¥å¿—å¤±è´¥: %v", err)
	}

	return datatypes.JSON(jsonData), nil
}

// validateNodeTrafficLogsData éªŒè¯NodeTrafficLogsæ•°æ®çš„å®Œæ•´æ€§
func validateNodeTrafficLogsData(nodeLog *model.NodeTrafficLogsPG) error {
	if nodeLog.DomainAsId == "" {
		return fmt.Errorf("DomainAsIdä¸èƒ½ä¸ºç©º")
	}

	// éªŒè¯çŠ¶æ€å­—æ®µ
	validStatuses := map[string]bool{
		"active":   true,
		"inactive": true,
	}

	if !validStatuses[nodeLog.Status] {
		// å¦‚æœçŠ¶æ€æ— æ•ˆï¼Œè®¾ç½®é»˜è®¤å€¼
		nodeLog.Status = "active"
	}

	return nil
}

// createNodeTrafficLogsIndexes ä¸ºNodeTrafficLogsè¡¨åˆ›å»ºé¢å¤–çš„ç´¢å¼•
func createNodeTrafficLogsIndexes(db *gorm.DB) error {
	log.Println("ğŸ” ä¸ºNodeTrafficLogsè¡¨åˆ›å»ºç´¢å¼•...")

	// ä¸ºdomain_as_idå­—æ®µåˆ›å»ºå”¯ä¸€ç´¢å¼•
	if err := db.Exec("CREATE UNIQUE INDEX IF NOT EXISTS idx_node_traffic_logs_domain_as_id_unique ON node_traffic_logs(domain_as_id)").Error; err != nil {
		return fmt.Errorf("åˆ›å»ºdomain_as_idå”¯ä¸€ç´¢å¼•å¤±è´¥: %v", err)
	}

	// ä¸ºstatuså­—æ®µåˆ›å»ºç´¢å¼•
	if err := db.Exec("CREATE INDEX IF NOT EXISTS idx_node_traffic_logs_status ON node_traffic_logs(status)").Error; err != nil {
		return fmt.Errorf("åˆ›å»ºstatusç´¢å¼•å¤±è´¥: %v", err)
	}

	// domain_idå­—æ®µå·²ä¸å­˜åœ¨ï¼Œä¸å†åˆ›å»ºç›¸å…³ç´¢å¼•

	// å¤åˆç´¢å¼• - status + created_at
	if err := db.Exec("CREATE INDEX IF NOT EXISTS idx_node_traffic_logs_status_created_at ON node_traffic_logs(status, created_at)").Error; err != nil {
		return fmt.Errorf("åˆ›å»ºå¤åˆç´¢å¼•å¤±è´¥: %v", err)
	}

	log.Println("âœ… NodeTrafficLogsç´¢å¼•åˆ›å»ºå®Œæˆ")
	return nil
}
