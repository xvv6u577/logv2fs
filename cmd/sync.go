package cmd

import (
	"context"
	"fmt"
	"log"
	"strings"
	"time"

	"github.com/google/uuid"
	"github.com/spf13/cobra"
	"github.com/xvv6u577/logv2fs/database"
	"github.com/xvv6u577/logv2fs/model"
	"go.mongodb.org/mongo-driver/bson"
	"go.mongodb.org/mongo-driver/mongo"
	"go.mongodb.org/mongo-driver/mongo/options"
	"gorm.io/gorm"
)

// SyncStats åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
type SyncStats struct {
	StartTime             time.Time `json:"start_time"`
	EndTime               time.Time `json:"end_time"`
	MongoToPostgresCount  int64     `json:"mongo_to_postgres_count"`
	PostgresToMongoCount  int64     `json:"postgres_to_mongo_count"`
	SkippedConflictsCount int64     `json:"skipped_conflicts_count"`
	Errors                []string  `json:"errors"`
	Mode                  string    `json:"mode"`
}

// syncCmd åŒå‘åŒæ­¥å‘½ä»¤
var syncCmd = &cobra.Command{
	Use:   "sync",
	Short: "åŒå‘åŒæ­¥MongoDBå’ŒPostgreSQLä¸­çš„user_traffic_logsæ•°æ®",
	Long: `è¿™ä¸ªå‘½ä»¤å®ç°MongoDBå’ŒPostgreSQLä¹‹é—´user_traffic_logsè¡¨çš„åŒå‘åŒæ­¥åŠŸèƒ½ã€‚

åŠŸèƒ½ç‰¹æ€§:
- ä»¥ email_as_id ä¸ºç´¢å¼•è¿›è¡Œæ•°æ®å¯¹æ¯”
- è‡ªåŠ¨æ£€æµ‹å¹¶åŒæ­¥ç¼ºå¤±çš„ç”¨æˆ·è®°å½•
- æ”¯æŒä¸‰ç§åŒæ­¥æ¨¡å¼ï¼šå•å‘å’ŒåŒå‘
- å†²çªå¤„ç†ï¼šè·³è¿‡å·²å­˜åœ¨çš„è®°å½•ï¼Œé¿å…æ•°æ®è¦†ç›–
- æ€§èƒ½ä¼˜åŒ–ï¼šæ”¯æŒæ‰¹å¤„ç†ï¼Œé€‚åˆå¤§æ•°æ®é‡åœºæ™¯
- è½»é‡åŒ–åŒæ­¥ï¼šè·³è¿‡æ—¶é—´åºåˆ—æ•°æ®ï¼ŒåªåŒæ­¥æ ¸å¿ƒç”¨æˆ·ä¿¡æ¯

åŒæ­¥æ¨¡å¼:
- mongo-to-postgres: åªä»MongoDBåŒæ­¥åˆ°PostgreSQL
- postgres-to-mongo: åªä»PostgreSQLåŒæ­¥åˆ°MongoDB  
- bidirectional: åŒå‘åŒæ­¥ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰

å®‰å…¨ç‰¹æ€§:
- åªæ·»åŠ ç¼ºå¤±è®°å½•ï¼Œä¸ä¿®æ”¹ç°æœ‰æ•°æ®
- è¯¦ç»†çš„è¿›åº¦ç›‘æ§å’Œé”™è¯¯æŠ¥å‘Š
- æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé‡å¤æ‰§è¡Œ

ä½¿ç”¨ç¤ºä¾‹:
  # åŒå‘åŒæ­¥ï¼ˆæ¨èï¼‰
  ./logv2fs sync

  # åªä»MongoDBåŒæ­¥åˆ°PostgreSQL
  ./logv2fs sync --mode=mongo-to-postgres

  # åªä»PostgreSQLåŒæ­¥åˆ°MongoDB
  ./logv2fs sync --mode=postgres-to-mongo

  # è‡ªå®šä¹‰æ‰¹é‡å¤§å°
  ./logv2fs sync --batch-size=200
`,
	Run: func(cmd *cobra.Command, args []string) {
		// è·å–å‘½ä»¤è¡Œå‚æ•°
		mode, _ := cmd.Flags().GetString("mode")
		batchSize, _ := cmd.Flags().GetInt("batch-size")

		log.Printf("ğŸ”„ å¼€å§‹æ‰§è¡Œæ•°æ®åº“åŒæ­¥ï¼Œæ¨¡å¼: %s", mode)

		// åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
		stats := &SyncStats{
			StartTime: time.Now(),
			Mode:      mode,
			Errors:    []string{},
		}

		// éªŒè¯æ•°æ®åº“è¿æ¥
		if err := validateDatabaseConnections(); err != nil {
			log.Fatalf("âŒ æ•°æ®åº“è¿æ¥éªŒè¯å¤±è´¥: %v", err)
		}

		// æ‰§è¡ŒåŒæ­¥
		switch mode {
		case "mongo-to-postgres":
			err := syncMongoToPostgres(batchSize, stats)
			if err != nil {
				log.Fatalf("âŒ MongoDBåˆ°PostgreSQLåŒæ­¥å¤±è´¥: %v", err)
			}
		case "postgres-to-mongo":
			err := syncPostgresToMongo(batchSize, stats)
			if err != nil {
				log.Fatalf("âŒ PostgreSQLåˆ°MongoDBåŒæ­¥å¤±è´¥: %v", err)
			}
		case "bidirectional":
			// åŒå‘åŒæ­¥ï¼šå…ˆMongoDBåˆ°PostgreSQLï¼Œå†PostgreSQLåˆ°MongoDB
			err := syncMongoToPostgres(batchSize, stats)
			if err != nil {
				log.Fatalf("âŒ MongoDBåˆ°PostgreSQLåŒæ­¥å¤±è´¥: %v", err)
			}

			err = syncPostgresToMongo(batchSize, stats)
			if err != nil {
				log.Fatalf("âŒ PostgreSQLåˆ°MongoDBåŒæ­¥å¤±è´¥: %v", err)
			}
		default:
			log.Fatalf("âŒ ä¸æ”¯æŒçš„åŒæ­¥æ¨¡å¼: %s", mode)
		}

		// è¾“å‡ºåŒæ­¥ç»Ÿè®¡ä¿¡æ¯
		stats.EndTime = time.Now()
		printSyncStats(stats)
	},
}

// validateDatabaseConnections éªŒè¯æ•°æ®åº“è¿æ¥
func validateDatabaseConnections() error {
	// éªŒè¯MongoDBè¿æ¥
	mongoClient := database.Client
	if mongoClient == nil {
		return fmt.Errorf("MongoDBè¿æ¥æœªåˆå§‹åŒ–")
	}

	// æµ‹è¯•MongoDBè¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	err := mongoClient.Ping(ctx, nil)
	if err != nil {
		return fmt.Errorf("MongoDBè¿æ¥æµ‹è¯•å¤±è´¥: %v", err)
	}

	// éªŒè¯PostgreSQLè¿æ¥
	postgresDB := database.GetPostgresDB()
	if postgresDB == nil {
		return fmt.Errorf("PostgreSQLè¿æ¥æœªåˆå§‹åŒ–")
	}

	// æµ‹è¯•PostgreSQLè¿æ¥
	sqlDB, err := postgresDB.DB()
	if err != nil {
		return fmt.Errorf("è·å–PostgreSQLåº•å±‚è¿æ¥å¤±è´¥: %v", err)
	}

	err = sqlDB.Ping()
	if err != nil {
		return fmt.Errorf("PostgreSQLè¿æ¥æµ‹è¯•å¤±è´¥: %v", err)
	}

	log.Println("âœ… æ•°æ®åº“è¿æ¥éªŒè¯æˆåŠŸ")
	return nil
}

// syncMongoToPostgres ä»MongoDBåŒæ­¥åˆ°PostgreSQL
func syncMongoToPostgres(batchSize int, stats *SyncStats) error {
	log.Println("ğŸ“¤ å¼€å§‹ä»MongoDBåŒæ­¥åˆ°PostgreSQL...")

	// è·å–æ•°æ®åº“è¿æ¥
	mongoClient := database.Client
	postgresDB := database.GetPostgresDB()

	// è·å–MongoDBé›†åˆ
	collection := database.OpenCollection(mongoClient, "USER_TRAFFIC_LOGS")

	// è·å–PostgreSQLä¸­å·²å­˜åœ¨çš„email_as_idåˆ—è¡¨
	existingEmails, err := getExistingEmailsFromPostgres(postgresDB)
	if err != nil {
		return fmt.Errorf("è·å–PostgreSQLå·²å­˜åœ¨é‚®ç®±åˆ—è¡¨å¤±è´¥: %v", err)
	}

	log.Printf("ğŸ“Š PostgreSQLä¸­å·²å­˜åœ¨ %d ä¸ªç”¨æˆ·è®°å½•", len(existingEmails))

	// åˆ†æ‰¹æŸ¥è¯¢MongoDBä¸­ä¸åœ¨PostgreSQLä¸­çš„è®°å½•
	var processed int64 = 0
	var synced int64 = 0
	var skipped int64 = 0

	// åˆ›å»ºæŸ¥è¯¢æ¡ä»¶ï¼šemail_as_idä¸åœ¨PostgreSQLçš„åˆ—è¡¨ä¸­
	filter := bson.M{
		"email_as_id": bson.M{"$nin": existingEmails},
	}

	// è®¡ç®—éœ€è¦åŒæ­¥çš„æ€»æ•°
	totalCount, err := collection.CountDocuments(context.Background(), filter)
	if err != nil {
		return fmt.Errorf("è®¡ç®—éœ€è¦åŒæ­¥çš„è®°å½•æ•°å¤±è´¥: %v", err)
	}

	log.Printf("ğŸ“ˆ å‘ç° %d ä¸ªéœ€è¦ä»MongoDBåŒæ­¥åˆ°PostgreSQLçš„è®°å½•", totalCount)

	if totalCount == 0 {
		log.Println("âœ… MongoDBä¸­æ²¡æœ‰æ–°çš„ç”¨æˆ·è®°å½•éœ€è¦åŒæ­¥åˆ°PostgreSQL")
		return nil
	}

	// åˆ†æ‰¹å¤„ç†
	for skip := int64(0); skip < totalCount; skip += int64(batchSize) {
		// è®¾ç½®æŸ¥è¯¢é€‰é¡¹
		findOptions := options.Find()
		findOptions.SetSkip(skip)
		findOptions.SetLimit(int64(batchSize))

		// æŸ¥è¯¢ä¸€æ‰¹æ•°æ®
		cursor, err := collection.Find(context.Background(), filter, findOptions)
		if err != nil {
			return fmt.Errorf("æŸ¥è¯¢MongoDBæ•°æ®å¤±è´¥: %v", err)
		}

		// å¤„ç†è¿™æ‰¹æ•°æ®
		var mongoUserLogs []model.UserTrafficLogs
		if err := cursor.All(context.Background(), &mongoUserLogs); err != nil {
			cursor.Close(context.Background())
			return fmt.Errorf("è§£æMongoDBæ•°æ®å¤±è´¥: %v", err)
		}
		cursor.Close(context.Background())

		// è½¬æ¢å¹¶ä¿å­˜åˆ°PostgreSQL
		for _, mongoUserLog := range mongoUserLogs {
			processed++

			// è½¬æ¢æ•°æ®ç»“æ„ï¼ˆè½»é‡åŒ–ï¼Œè·³è¿‡æ—¶é—´åºåˆ—æ•°æ®ï¼‰
			pgUserLog, err := convertUserTrafficLogsToPostgresLight(mongoUserLog)
			if err != nil {
				log.Printf("âš ï¸  è½¬æ¢ç”¨æˆ·è®°å½•å¤±è´¥ [%s]: %v", mongoUserLog.Email_As_Id, err)
				stats.Errors = append(stats.Errors, fmt.Sprintf("è½¬æ¢ç”¨æˆ·è®°å½•å¤±è´¥ [%s]: %v", mongoUserLog.Email_As_Id, err))
				continue
			}

			// ä¿å­˜åˆ°PostgreSQL
			if err := postgresDB.Create(&pgUserLog).Error; err != nil {
				// æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤é”®é”™è¯¯ï¼ˆå¯èƒ½åœ¨æ‰¹å¤„ç†é—´éš™æœ‰æ–°å¢è®°å½•ï¼‰
				if isUniqueConstraintError(err) {
					skipped++
					log.Printf("â­ï¸  è·³è¿‡é‡å¤è®°å½•: %s", mongoUserLog.Email_As_Id)
					continue
				}

				log.Printf("âš ï¸  ä¿å­˜ç”¨æˆ·è®°å½•åˆ°PostgreSQLå¤±è´¥ [%s]: %v", mongoUserLog.Email_As_Id, err)
				stats.Errors = append(stats.Errors, fmt.Sprintf("ä¿å­˜ç”¨æˆ·è®°å½•å¤±è´¥ [%s]: %v", mongoUserLog.Email_As_Id, err))
				continue
			}

			synced++
		}

		// æ‰“å°è¿›åº¦
		if processed%int64(batchSize*5) == 0 || processed == totalCount {
			log.Printf("ğŸ“ˆ MongoDBâ†’PostgreSQL åŒæ­¥è¿›åº¦: %d/%d (å·²åŒæ­¥: %d, å·²è·³è¿‡: %d)",
				processed, totalCount, synced, skipped)
		}
	}

	stats.MongoToPostgresCount = synced
	log.Printf("âœ… MongoDBâ†’PostgreSQL åŒæ­¥å®Œæˆ: å…±å¤„ç† %d æ¡è®°å½•ï¼ŒæˆåŠŸåŒæ­¥ %d æ¡ï¼Œè·³è¿‡ %d æ¡",
		processed, synced, skipped)

	return nil
}

// syncPostgresToMongo ä»PostgreSQLåŒæ­¥åˆ°MongoDB
func syncPostgresToMongo(batchSize int, stats *SyncStats) error {
	log.Println("ğŸ“¤ å¼€å§‹ä»PostgreSQLåŒæ­¥åˆ°MongoDB...")

	// è·å–æ•°æ®åº“è¿æ¥
	mongoClient := database.Client
	postgresDB := database.GetPostgresDB()

	// è·å–MongoDBé›†åˆ
	collection := database.OpenCollection(mongoClient, "USER_TRAFFIC_LOGS")

	// è·å–MongoDBä¸­å·²å­˜åœ¨çš„email_as_idåˆ—è¡¨
	existingEmails, err := getExistingEmailsFromMongo(collection)
	if err != nil {
		return fmt.Errorf("è·å–MongoDBå·²å­˜åœ¨é‚®ç®±åˆ—è¡¨å¤±è´¥: %v", err)
	}

	log.Printf("ğŸ“Š MongoDBä¸­å·²å­˜åœ¨ %d ä¸ªç”¨æˆ·è®°å½•", len(existingEmails))

	// åˆ†æ‰¹æŸ¥è¯¢PostgreSQLä¸­ä¸åœ¨MongoDBä¸­çš„è®°å½•
	var processed int64 = 0
	var synced int64 = 0
	var skipped int64 = 0

	// æŸ¥è¯¢PostgreSQLä¸­email_as_idä¸åœ¨MongoDBåˆ—è¡¨ä¸­çš„è®°å½•æ•°
	var totalCount int64
	query := postgresDB.Model(&model.UserTrafficLogsPG{})
	if len(existingEmails) > 0 {
		query = query.Where("email_as_id NOT IN ?", existingEmails)
	}

	err = query.Count(&totalCount).Error
	if err != nil {
		return fmt.Errorf("è®¡ç®—éœ€è¦åŒæ­¥çš„è®°å½•æ•°å¤±è´¥: %v", err)
	}

	log.Printf("ğŸ“ˆ å‘ç° %d ä¸ªéœ€è¦ä»PostgreSQLåŒæ­¥åˆ°MongoDBçš„è®°å½•", totalCount)

	if totalCount == 0 {
		log.Println("âœ… PostgreSQLä¸­æ²¡æœ‰æ–°çš„ç”¨æˆ·è®°å½•éœ€è¦åŒæ­¥åˆ°MongoDB")
		return nil
	}

	// åˆ†æ‰¹å¤„ç†
	for offset := int64(0); offset < totalCount; offset += int64(batchSize) {
		var pgUserLogs []model.UserTrafficLogsPG

		// æŸ¥è¯¢ä¸€æ‰¹æ•°æ®
		query := postgresDB.Model(&model.UserTrafficLogsPG{})
		if len(existingEmails) > 0 {
			query = query.Where("email_as_id NOT IN ?", existingEmails)
		}

		err := query.Offset(int(offset)).Limit(batchSize).Find(&pgUserLogs).Error
		if err != nil {
			return fmt.Errorf("æŸ¥è¯¢PostgreSQLæ•°æ®å¤±è´¥: %v", err)
		}

		// è½¬æ¢å¹¶ä¿å­˜åˆ°MongoDB
		for _, pgUserLog := range pgUserLogs {
			processed++

			// è½¬æ¢æ•°æ®ç»“æ„ï¼ˆè½»é‡åŒ–ï¼Œè·³è¿‡æ—¶é—´åºåˆ—æ•°æ®ï¼‰
			mongoUserLog, err := convertUserTrafficLogsToMongoLight(pgUserLog)
			if err != nil {
				log.Printf("âš ï¸  è½¬æ¢ç”¨æˆ·è®°å½•å¤±è´¥ [%s]: %v", pgUserLog.EmailAsId, err)
				stats.Errors = append(stats.Errors, fmt.Sprintf("è½¬æ¢ç”¨æˆ·è®°å½•å¤±è´¥ [%s]: %v", pgUserLog.EmailAsId, err))
				continue
			}

			// ä¿å­˜åˆ°MongoDB
			_, err = collection.InsertOne(context.Background(), mongoUserLog)
			if err != nil {
				// æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤é”®é”™è¯¯
				if isDuplicateKeyError(err) {
					skipped++
					log.Printf("â­ï¸  è·³è¿‡é‡å¤è®°å½•: %s", pgUserLog.EmailAsId)
					continue
				}

				log.Printf("âš ï¸  ä¿å­˜ç”¨æˆ·è®°å½•åˆ°MongoDBå¤±è´¥ [%s]: %v", pgUserLog.EmailAsId, err)
				stats.Errors = append(stats.Errors, fmt.Sprintf("ä¿å­˜ç”¨æˆ·è®°å½•å¤±è´¥ [%s]: %v", pgUserLog.EmailAsId, err))
				continue
			}

			synced++
		}

		// æ‰“å°è¿›åº¦
		if processed%int64(batchSize*5) == 0 || processed == totalCount {
			log.Printf("ğŸ“ˆ PostgreSQLâ†’MongoDB åŒæ­¥è¿›åº¦: %d/%d (å·²åŒæ­¥: %d, å·²è·³è¿‡: %d)",
				processed, totalCount, synced, skipped)
		}
	}

	stats.PostgresToMongoCount = synced
	log.Printf("âœ… PostgreSQLâ†’MongoDB åŒæ­¥å®Œæˆ: å…±å¤„ç† %d æ¡è®°å½•ï¼ŒæˆåŠŸåŒæ­¥ %d æ¡ï¼Œè·³è¿‡ %d æ¡",
		processed, synced, skipped)

	return nil
}

// getExistingEmailsFromPostgres è·å–PostgreSQLä¸­å·²å­˜åœ¨çš„email_as_idåˆ—è¡¨
func getExistingEmailsFromPostgres(db *gorm.DB) ([]string, error) {
	var emails []string
	err := db.Model(&model.UserTrafficLogsPG{}).Pluck("email_as_id", &emails).Error
	if err != nil {
		return nil, err
	}
	return emails, nil
}

// getExistingEmailsFromMongo è·å–MongoDBä¸­å·²å­˜åœ¨çš„email_as_idåˆ—è¡¨
func getExistingEmailsFromMongo(collection *mongo.Collection) ([]string, error) {
	ctx := context.Background()

	// ä½¿ç”¨distinctè·å–æ‰€æœ‰ä¸é‡å¤çš„email_as_id
	emails, err := collection.Distinct(ctx, "email_as_id", bson.M{})
	if err != nil {
		return nil, err
	}

	// è½¬æ¢ä¸ºå­—ç¬¦ä¸²åˆ‡ç‰‡
	var emailStrings []string
	for _, email := range emails {
		if emailStr, ok := email.(string); ok {
			emailStrings = append(emailStrings, emailStr)
		}
	}

	return emailStrings, nil
}

// convertUserTrafficLogsToPostgresLight è½»é‡åŒ–è½¬æ¢ï¼šMongoDB â†’ PostgreSQLï¼ˆè·³è¿‡æ—¶é—´åºåˆ—æ•°æ®ï¼‰
func convertUserTrafficLogsToPostgresLight(mongoUserLog model.UserTrafficLogs) (model.UserTrafficLogsPG, error) {
	pgUserLog := model.UserTrafficLogsPG{
		ID:           uuid.New(),
		EmailAsId:    mongoUserLog.Email_As_Id,
		Password:     mongoUserLog.Password,
		UUID:         mongoUserLog.UUID,
		Role:         mongoUserLog.Role,
		Status:       mongoUserLog.Status,
		Name:         mongoUserLog.Name,
		Token:        mongoUserLog.Token,
		RefreshToken: mongoUserLog.Refresh_token,
		UserID:       mongoUserLog.User_id,
		Used:         mongoUserLog.Used,
		Credit:       mongoUserLog.Credit,
		CreatedAt:    mongoUserLog.CreatedAt,
		UpdatedAt:    mongoUserLog.UpdatedAt,
		// æ³¨æ„ï¼šæ•…æ„è·³è¿‡æ—¶é—´åºåˆ—æ•°æ®çš„è½¬æ¢
		// HourlyLogs, DailyLogs, MonthlyLogs, YearlyLogs ä¿æŒä¸ºç©º
	}

	return pgUserLog, nil
}

// convertUserTrafficLogsToMongoLight è½»é‡åŒ–è½¬æ¢ï¼šPostgreSQL â†’ MongoDBï¼ˆè·³è¿‡æ—¶é—´åºåˆ—æ•°æ®ï¼‰
func convertUserTrafficLogsToMongoLight(pgUserLog model.UserTrafficLogsPG) (model.UserTrafficLogs, error) {
	mongoUserLog := model.UserTrafficLogs{
		Email_As_Id:   pgUserLog.EmailAsId,
		Password:      pgUserLog.Password,
		UUID:          pgUserLog.UUID,
		Role:          pgUserLog.Role,
		Status:        pgUserLog.Status,
		Name:          pgUserLog.Name,
		Token:         pgUserLog.Token,
		Refresh_token: pgUserLog.RefreshToken,
		User_id:       pgUserLog.UserID,
		Used:          pgUserLog.Used,
		Credit:        pgUserLog.Credit,
		CreatedAt:     pgUserLog.CreatedAt,
		UpdatedAt:     pgUserLog.UpdatedAt,
		// æ³¨æ„ï¼šæ•…æ„è·³è¿‡æ—¶é—´åºåˆ—æ•°æ®çš„è½¬æ¢
		// HourlyLogs, DailyLogs, MonthlyLogs, YearlyLogs ä¿æŒä¸ºç©º
	}

	return mongoUserLog, nil
}

// isUniqueConstraintError æ£€æŸ¥æ˜¯å¦æ˜¯å”¯ä¸€çº¦æŸé”™è¯¯
func isUniqueConstraintError(err error) bool {
	// PostgreSQLå”¯ä¸€çº¦æŸé”™è¯¯é€šå¸¸åŒ…å«"duplicate key"æˆ–"UNIQUE constraint"
	errStr := err.Error()
	return strings.Contains(errStr, "duplicate key") ||
		strings.Contains(errStr, "UNIQUE constraint") ||
		strings.Contains(errStr, "uniqueIndex")
}

// isDuplicateKeyError æ£€æŸ¥æ˜¯å¦æ˜¯MongoDBé‡å¤é”®é”™è¯¯
func isDuplicateKeyError(err error) bool {
	// MongoDBé‡å¤é”®é”™è¯¯é€šå¸¸åŒ…å«"duplicate key"æˆ–é”™è¯¯ä»£ç 11000
	errStr := err.Error()
	return strings.Contains(errStr, "duplicate key") ||
		strings.Contains(errStr, "E11000") ||
		strings.Contains(errStr, "duplicate")
}

// printSyncStats è¾“å‡ºåŒæ­¥ç»Ÿè®¡ä¿¡æ¯
func printSyncStats(stats *SyncStats) {
	duration := stats.EndTime.Sub(stats.StartTime)

	log.Println("\n" + strings.Repeat("=", 60))
	log.Println("ğŸ“Š æ•°æ®åº“åŒæ­¥ç»Ÿè®¡æŠ¥å‘Š")
	log.Println(strings.Repeat("=", 60))
	log.Printf("ğŸ• å¼€å§‹æ—¶é—´: %s", stats.StartTime.Format("2006-01-02 15:04:05"))
	log.Printf("ğŸ•‘ ç»“æŸæ—¶é—´: %s", stats.EndTime.Format("2006-01-02 15:04:05"))
	log.Printf("â±ï¸  æ€»è€—æ—¶: %v", duration)
	log.Printf("ğŸ”„ åŒæ­¥æ¨¡å¼: %s", stats.Mode)
	log.Println(strings.Repeat("-", 60))
	log.Printf("ğŸ“¤ MongoDB â†’ PostgreSQL: %d æ¡è®°å½•", stats.MongoToPostgresCount)
	log.Printf("ğŸ“¥ PostgreSQL â†’ MongoDB: %d æ¡è®°å½•", stats.PostgresToMongoCount)
	log.Printf("ğŸ“Š æ€»åŒæ­¥è®°å½•æ•°: %d æ¡", stats.MongoToPostgresCount+stats.PostgresToMongoCount)
	log.Printf("â­ï¸  è·³è¿‡å†²çªè®°å½•: %d æ¡", stats.SkippedConflictsCount)

	if len(stats.Errors) > 0 {
		log.Println(strings.Repeat("-", 60))
		log.Printf("âš ï¸  é”™è¯¯æ•°é‡: %d", len(stats.Errors))
		for i, err := range stats.Errors {
			if i < 10 { // åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
				log.Printf("   %d. %s", i+1, err)
			}
		}
		if len(stats.Errors) > 10 {
			log.Printf("   ... ä»¥åŠå…¶ä»– %d ä¸ªé”™è¯¯", len(stats.Errors)-10)
		}
	}

	log.Println(strings.Repeat("=", 60))

	if len(stats.Errors) == 0 {
		log.Println("âœ… åŒæ­¥å®Œæˆï¼Œæ— é”™è¯¯å‘ç”Ÿ")
	} else {
		log.Println("âš ï¸  åŒæ­¥å®Œæˆï¼Œä½†å‘ç”Ÿäº†ä¸€äº›é”™è¯¯ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
	}
}

func init() {
	rootCmd.AddCommand(syncCmd)

	// æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
	syncCmd.Flags().StringP("mode", "m", "bidirectional", "åŒæ­¥æ¨¡å¼: mongo-to-postgres, postgres-to-mongo, bidirectional")
	syncCmd.Flags().IntP("batch-size", "b", 100, "æ‰¹å¤„ç†å¤§å°ï¼Œé€‚åˆè°ƒæ•´ä»¥ä¼˜åŒ–æ€§èƒ½")
}
